<!DOCTYPE html>
<html>
<head>
    <title>MediaPipe Hands - Web</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <style>
        #output_canvas {
            transform: scaleX(-1); /* Espejo para efecto espejo */
        }
        .container {
            position: relative;
            width: 100%;
            max-width: 720px;
        }
        .camera-feed, .output-canvas {
            position: absolute;
            left: 0;
            top: 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <video class="camera-feed" id="input_video" autoplay playsinline></video>
        <canvas class="output-canvas" id="output_canvas" width="720" height="480"></canvas>
    </div>
    <p id="status">Inicializando...</p>

    <script>
        const videoElement = document.getElementById('input_video');
        const canvasElement = document.getElementById('output_canvas');
        const canvasCtx = canvasElement.getContext('2d');
        const statusElement = document.getElementById('status');

        // 1. Configurar MediaPipe Hands
        const hands = new Hands({
            locateFile: (file) => {
                return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
            }
        });

        hands.setOptions({
            selfieMode: true,
            maxNumHands: 2,
            modelComplexity: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        // 2. Procesar resultados
        hands.onResults((results) => {
            statusElement.innerText = "Detección activa";
            
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(
                results.image, 0, 0, canvasElement.width, canvasElement.height);
            
            // Dibujar landmarks si se detectan manos
            if (results.multiHandLandmarks) {
                for (const landmarks of results.multiHandLandmarks) {
                    drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, 
                        {color: '#00FF00', lineWidth: 5});
                    drawLandmarks(canvasCtx, landmarks, 
                        {color: '#FF0000', lineWidth: 2});
                }
                statusElement.innerText = `Manos detectadas: ${results.multiHandLandmarks.length}`;
            } else {
                statusElement.innerText = "Acerca tu mano a la cámara...";
            }
            
            canvasCtx.restore();
        });

        // 3. Configurar cámara
        const camera = new Camera(videoElement, {
            onFrame: async () => {
                await hands.send({image: videoElement});
            },
            width: 720,
            height: 480
        });

        // 4. Manejar errores
        camera.start().then(() => {
            statusElement.innerText = "Cámara iniciada";
        }).catch((error) => {
            statusElement.innerHTML = `Error: ${error}<br>Requerimientos:<br>
                - Usar HTTPS/localhost<br>
                - Permitir acceso a cámara<br>
                - Navegador compatible (Chrome, Edge, Firefox)`;
            console.error("Error en cámara:", error);
        });
    </script>
</body>
</html>